#!/bin/bash
#SBATCH -J mlp                # Job name
#SBATCH -o /home/gg462/spectraltextanomoly/.output/%j.out                  # Name of stdout output log file (%j expands to jobID)
#SBATCH -e /home/gg462/spectraltextanomoly/.output/%j.err                  # Name of stderr output log file (%j expands to jobID)
#SBATCH -N 1                                 # Total number of nodes requested
#SBATCH -n 4                                 # Total number of cores requested
#SBATCH --mem=20000                          # Total amount of (real) memory requested (per node)
#SBATCH -t 24:00:00                          # Time limit (hh:mm:ss)
#SBATCH --partition=lil        # Request partition for resource allocation
#SBATCH --gres=gpu:1                        # Specify a list of generic consumable resources (per node)
#SBATCH --nodelist=lil-compute-03
source ~/anaconda3/etc/profile.d/conda.sh
conda activate pqa
cd /home/gg462/spectraltextanomoly
PYTHONPATH=$(pwd) python train.py --wandb --notes 'exp' --do_train --do_eval --eval_test --model 'bert-base-uncased' --classifier 'spectral' --filter 'high' --attack 'textfooler' --dataset 'agnews' --seed 46 --eval_metric f1 --num_train_epochs 10 --eval_per_epoch 4 --train_batch_size 32 --eval_batch_size 32 --gradient_accumulation_steps 1  --learning_rate 1e-4