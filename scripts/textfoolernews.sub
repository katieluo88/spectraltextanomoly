#!/bin/bash
#SBATCH -J 1e-4mlp                # Job name
#SBATCH -o /home/gg462/spectraltextanomoly/.output/%j.out                  # Name of stdout output log file (%j expands to jobID)
#SBATCH -e /home/gg462/spectraltextanomoly/.output/%j.err                  # Name of stderr output log file (%j expands to jobID)
#SBATCH -N 1                                 # Total number of nodes requested
#SBATCH -n 4                                 # Total number of cores requested
#SBATCH --mem=20000                          # Total amount of (real) memory requested (per node)
#SBATCH -t 24:00:00                          # Time limit (hh:mm:ss)
#SBATCH --partition=lil        # Request partition for resource allocation
#SBATCH --gres=gpu:1                        # Specify a list of generic consumable resources (per node)
#SBATCH --nodelist=lil-compute-03
source ~/anaconda3/etc/profile.d/conda.sh
conda activate pqa
cd /home/gg462/spectraltextanomoly
PYTHONPATH=$(pwd) python train.py --wandb --notes 'mlp lr?' --do_train --do_eval --eval_test --model 'bert-base-uncased' --classifier 'mlp' --attack 'textfooler' --dataset 'agnews' --seed 46 --eval_metric f1 --num_train_epochs 10 --eval_per_epoch 4 --output_dir .experiment --scheduler constant --train_batch_size 40 --eval_batch_size 10 --gradient_accumulation_steps 4  --learning_rate 1e-4